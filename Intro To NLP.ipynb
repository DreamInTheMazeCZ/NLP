{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intro\n\n## 원문 : https://www.kaggle.com/code/matleonard/intro-to-nlp\n\n## Intro To NLP By MAT LEONARD, DanB, Alexis Cook, Ryan Holbrook\n\n#### (해당 문서는 제가 작성한 내용이 아니고 번역만 했습니다.)\n\n\n데이터는 시계열, 센서 정보, 이미지, 범주형 레이블 등 다양한 형태로 제공됩니다. 그러나 텍스트는 사용법을 아는 사람들에게 여전히 가장 가치 있는 데이터 중 하나입니다.\n\n**자연어처리(Natural Language Processing)**에 대한 이 과정에서는 NLP 라이브러리인 spaCy를 사용하여 텍스트 작업에 있어 가장 중요한 몇 가지 작업을 수행할 것입니다.\n\n이제 다음 용도로 spaCy를 사용할 수 있습니다.\n\n* 기본적인 텍스트 처리 및 패턴 매칭\n* 텍스트로 머신러닝 모델 구축\n* 단어와 문서의 의미를 수치로 표현하기 위한 임베딩으로 텍스트 표현(Representing text with word embeddings that numerically capture the meaning of words and documents)","metadata":{}},{"cell_type":"markdown","source":"이 과정을 공부하기 위해 머신러닝 - scikit-learn에 대한 선행학습이 필요합니다.\n\n[Intro to Machine Learning] https://www.kaggle.com/learn/intro-to-machine-learning 및\n\n[Intermediate Machine Learning] https://www.kaggle.com/learn/intermediate-machine-learning\n\n을 통해 기초를 공부하시길 권장합니다.","metadata":{}},{"cell_type":"markdown","source":"## NLP와 spaCy\n\nspaCy는 NLP를 선도하는 라이브러리로, NLP 중 가장 인기 있는 파이썬 프레임워크 중 하나가 되었습다. spaCy 직관적이고 훌륭하게 [문서]를 다룹니다.\n\nhttps://spacy.io/usage\n\nspaCy는 언어별로, 문장길이별로 다른 **모델**에 의존합니다. \n\n'spacy.load'를 통해 spaCy 모델을 로드할 수 있고, 예로 영어 모델을 로드하는 방법은 다음과 같습니다.","metadata":{}},{"cell_type":"code","source":"import spacy\nnlp = spacy.load('en_core_web_sm')","metadata":{"execution":{"iopub.status.busy":"2022-08-22T08:40:11.103790Z","iopub.execute_input":"2022-08-22T08:40:11.104305Z","iopub.status.idle":"2022-08-22T08:40:11.854238Z","shell.execute_reply.started":"2022-08-22T08:40:11.104269Z","shell.execute_reply":"2022-08-22T08:40:11.852874Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"모델을 불러온 후 다음과 같이 텍스트를 처리할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"doc = nlp(\"Tea is healthy and calming, don't you think?\")","metadata":{"execution":{"iopub.status.busy":"2022-08-22T08:40:11.856164Z","iopub.execute_input":"2022-08-22T08:40:11.856527Z","iopub.status.idle":"2022-08-22T08:40:11.873025Z","shell.execute_reply.started":"2022-08-22T08:40:11.856495Z","shell.execute_reply":"2022-08-22T08:40:11.871751Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"방금 생성한 'doc' 오브젝트로 다음과 같은 작업을 할 수 있습니다.\n\n## Tokenizing (토큰화)\n\n토큰화를 진행하면 **tokens**를 포함하는 텍스트 각각의 개체를 반환합니다. 토큰은 개별 단어나 구두점과 같은 문서의 텍스트 단위입니다. 영어를 예로 들면 토큰화는 \"don't\"를 \"do\"와 \"not\"(\"n't\")이라는 두 개의 토큰으로 나눕니다. 이런 작업을 반복하여 토큰화를 진행합니다.\n\n### Word Tokenizing (단어 토큰화)\n\n구두점이나 특수문자를 전부 제거하는 정제 작업\n\n### Sentence Tokenizing (문장 토큰화)\n\n해당하는 문단 내에서 문장 단위로 구분하는 작업","metadata":{}},{"cell_type":"code","source":"for token in doc:\n    print(token)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T08:40:11.874582Z","iopub.execute_input":"2022-08-22T08:40:11.874900Z","iopub.status.idle":"2022-08-22T08:40:11.879491Z","shell.execute_reply.started":"2022-08-22T08:40:11.874871Z","shell.execute_reply":"2022-08-22T08:40:11.878457Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"반복문을 통해 토큰화를 진행할 수 있습니다. 이러한 개별 토큰은 다음의 정보와 함께 제공됩니다. 대부분의 경우 중요한 것은 'token.lemma_'와 'token.is_stop'입니다.\n\n## Text Preprocessing (텍스트 전처리)\n\n단어를 통해 모델링 방법을 개선하기 위한 몇 가지 유형의 텍스트 전처리 방법이 있습니다.\n첫 번째는 **Lemmatizing**입니다.\n\"Lemma\"는 단어의 기본 형태로, 영어를 예로 들면 \"Walk\"는 \"Walking\"이라는 단어의 기본형입니다. 즉, \"Walking\"라는 단어를 Lemmatizing을 진행하면 \"Walking\"은 \"Walk\"로 변환됩니다.\n\n두 번째는 **Stop Words** 제거입니다. 스톱워드란 문장에서 자주 사용되지만 필요한 정보를 포함하지 않는 단어입니다. 영어로 예를 들면 \"the\", \"is\", \"and\", \"but\", \"not\" 등이 있습니다.\n\nspaCy token의 `token.lemma_`을 통해 Lemma(단어의 기본 형태)를 반환하고, `token.is_stop`을 통해 Stop Words의 참, 거짓 값(Boolean)을 반환합니다.","metadata":{}},{"cell_type":"code","source":"print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\nprint(\"-\"*40)\nfor token in doc:\n    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")","metadata":{"execution":{"iopub.status.busy":"2022-08-22T08:40:11.881775Z","iopub.execute_input":"2022-08-22T08:40:11.882123Z","iopub.status.idle":"2022-08-22T08:40:11.893537Z","shell.execute_reply.started":"2022-08-22T08:40:11.882073Z","shell.execute_reply":"2022-08-22T08:40:11.892528Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"단어의 기본형과 스톱워드를 식별하는 것이 중요한 이유로는 텍스트 데이터에는 많은 노이즈가 실제 필요한 정보와 섞여 있는 경우가 대다수입니다. 예제로 사용한 문장에서 정보를 담고 있는 실제 필요한 단어로는 차(Tea), 건강(Healthy), 진정(Calming)입니다. 스톱워드를 제거하면 예측 모델에 필요한 단어를 효과적으로 사용할 수 있고, 또한 Lemmatizing은 같은 단어의 여러 형태를 하나의 기본 형태로 만들어줌으로써 분석이 용이하게 해줍니다.\n\n그러나 Lemmatizing이나 스톱워드 삭제는 때에 따라 모델의 성능저하를 야기할 수 있습니다. 따라서 이런 전처리 과정은 하이퍼파라미터 최적화의 일부로 처리하면 좋습니다.\n\n(기본 모델을 적용해보고 하이퍼파라미터 튜닝과 같이 성능변화를 비교해보라는 의미인 듯 합니다.)","metadata":{}},{"cell_type":"markdown","source":"## Pattern Matching\n\n또 하나의 일반적인 NLP 작업으로는 문단 또는 문서 전체에서 어절 또는 구를 일치시키는 것입니다. 정규표현식을 통해서도 패턴 매칭이 가능하지만 spaCy를 통한 패턴 매칭 기능이 조금 더 사용하기 쉽습니다.\n\n개별 토큰을 일치시키기 위해 'Matcher'를 사용합니다. 그 중 용어 목록을 일치시키려면 \"PraseMatcher\"를 불러오는 것이 효율적입니다. 예로 일부 텍스트에서 다른 스마트폰 모델이 표시되는 위치를 찾으려면 관심 있는 모델 이름에 대한 패턴을 만들 수 있습니다. 먼저 \"PraseMatcher\" 를 생성합니다.","metadata":{}},{"cell_type":"code","source":"from spacy.matcher import PhraseMatcher\nmatcher = PhraseMatcher(nlp.vocab, attr='LOWER')","metadata":{"execution":{"iopub.status.busy":"2022-08-22T08:40:11.894813Z","iopub.execute_input":"2022-08-22T08:40:11.895507Z","iopub.status.idle":"2022-08-22T08:40:11.904763Z","shell.execute_reply.started":"2022-08-22T08:40:11.895472Z","shell.execute_reply":"2022-08-22T08:40:11.903671Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"'matcher' 오브젝트는 \"PhraseMatcher\"의 어휘를 통해 생성됩니다. 예제에서는 이전에 생성한 작은 영어 모델을 사용하고 있습니다. 'attr' 옵션 'LOWER'를 통해 PhraseMatcher의 어휘를 소문자로 만들어 대소문자를 구분하지 않도록 합니다.\n\n그다음 텍스트에서 일치시킬 용어 목록을 생성합니다. \"PhraseMatcher\"에는 패턴이 Document 오브젝트로 필요한데, 이를 얻는 가장 쉬운 방법이 'nlp' 모델을 통한 목록 이해입니다.","metadata":{}},{"cell_type":"code","source":"terms = ['Galaxy Note', 'iPhone 11', 'iPhone XS', 'Google Pixel']\npatterns = [nlp(text) for text in terms]\nmatcher.add(\"TerminologyList\", patterns)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T08:40:11.906321Z","iopub.execute_input":"2022-08-22T08:40:11.907211Z","iopub.status.idle":"2022-08-22T08:40:11.941945Z","shell.execute_reply.started":"2022-08-22T08:40:11.907171Z","shell.execute_reply":"2022-08-22T08:40:11.940984Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"다음으로 텍스트에서 문서를 만들어 검색한 후 \"PhraseMatcher\"를 사용하여 문서에서 용어가 등장하는 위치를 찾습니다.","metadata":{}},{"cell_type":"code","source":"# Borrowed from https://daringfireball.net/linked/2019/09/21/patel-11-pro\ntext_doc = nlp(\"Glowing review overall, and some really interesting side-by-side \"\n               \"photography tests pitting the iPhone 11 Pro against the \"\n               \"Galaxy Note 10 Plus and last year’s iPhone XS and Google Pixel 3.\") \nmatches = matcher(text_doc)\nprint(matches)","metadata":{"execution":{"iopub.status.busy":"2022-08-22T08:40:11.943394Z","iopub.execute_input":"2022-08-22T08:40:11.944012Z","iopub.status.idle":"2022-08-22T08:40:11.964555Z","shell.execute_reply.started":"2022-08-22T08:40:11.943977Z","shell.execute_reply":"2022-08-22T08:40:11.963714Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"여기서 일치하는 항목은 일치 ID의 튜플과 구문의 시작 및 끝 위치입니다.","metadata":{}},{"cell_type":"code","source":"match_id, start, end = matches[0]\nprint(nlp.vocab.strings[match_id], text_doc[start:end])","metadata":{"execution":{"iopub.status.busy":"2022-08-22T08:40:11.965834Z","iopub.execute_input":"2022-08-22T08:40:11.966194Z","iopub.status.idle":"2022-08-22T08:40:11.971734Z","shell.execute_reply.started":"2022-08-22T08:40:11.966161Z","shell.execute_reply":"2022-08-22T08:40:11.970796Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"# Your Turn\n\nNLP용 spaCy를 몇 가지 사용법을 공부했으니, 이번에는 **[Yelp 리뷰 분석]**에 도전해보세요.\n\nhttps://www.kaggle.com/kernels/fork/6061023","metadata":{}},{"cell_type":"markdown","source":"---\n\n\n\n\n*Have questions or comments? Visit the [course discussion forum](https://www.kaggle.com/learn/natural-language-processing/discussion) to chat with other learners.*","metadata":{}}]}